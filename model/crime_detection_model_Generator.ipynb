{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime Detection Model Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "df = pd.read_csv('crime_data.csv')\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\", dayfirst=False)\n",
    "df['hour'] = pd.to_datetime(df['Time'], format='%H:%M', errors='coerce').dt.hour.fillna(0).astype(int)\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['day'] = df['Date'].dt.day\n",
    "df['weekday'] = df['Date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crime_encoder.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~# Encode categorical variables\n",
    "le_location = LabelEncoder()\n",
    "df['Location_encoded'] = le_location.fit_transform(df['Locality_Name'])\n",
    "joblib.dump(le_location, 'location_encoder.pkl')\n",
    "\n",
    "le_crime = LabelEncoder()\n",
    "df['Crime_encoded'] = le_crime.fit_transform(df['Crime_Type'])\n",
    "joblib.dump(le_crime, 'crime_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection and scaling\n",
    "X = df[['Location_encoded', 'Crime_encoded', 'month', 'day', 'weekday', 'hour']].values\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "X_scaled = X_scaled.reshape((X_scaled.shape[0], X_scaled.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Conv1D + BiLSTM Autoencoder\n",
    "input_layer = tf.keras.Input(shape=(6, 1))\n",
    "x = tf.keras.layers.Conv1D(32, kernel_size=2, padding='same', activation='relu')(input_layer)\n",
    "x = tf.keras.layers.MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(x)\n",
    "x = tf.keras.layers.UpSampling1D(size=2)(x)\n",
    "x = tf.keras.layers.Conv1D(1, kernel_size=2, padding='same', activation='sigmoid')(x)\n",
    "\n",
    "autoencoder = tf.keras.Model(inputs=input_layer, outputs=x)\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "autoencoder.compile(optimizer='adam', loss=MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 0.0347\n",
      "Epoch 2/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0013\n",
      "Epoch 3/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0011\n",
      "Epoch 4/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 9.4074e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 7.7584e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 6.4035e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.4974e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0298e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 4.4934e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 3.9355e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 3.5334e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 3.1116e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 2.8877e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 2.5893e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 2.3662e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 2.1891e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.9966e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.8438e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.6771e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.6044e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.4377e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.3107e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.2570e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.1785e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.1141e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.0834e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.0162e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.0052e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 9.6597e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 9.3265e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c1b0163550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=30, batch_size=32, verbose=1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "autoencoder.save('conv_bilstm_autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and calculate reconstruction error\n",
    "reconstructed = autoencoder.predict(X_scaled, verbose=0)\n",
    "mse = np.mean(np.power(X_scaled - reconstructed, 2), axis=(1, 2))\n",
    "df['reconstruction_error'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top anomalies based on reconstruction error:\n",
      "   Locality_Name           Crime_Type                Date              Time  \\\n",
      "5      Falaknuma              ASSAULT 2020-01-01 05:00:00  01-01-2020 17:09   \n",
      "6      Charminar     VEHICLE - STOLEN 2020-01-01 06:00:00  01-01-2020 14:08   \n",
      "16    gachibowli         DRUG OFFENSE 2020-01-01 16:00:00  02-01-2020 02:57   \n",
      "17    Patancheru                ARSON 2020-01-01 17:00:00  01-01-2020 23:09   \n",
      "52    gachibowli  PUBLIC INTOXICATION 2020-01-03 04:00:00  03-01-2020 22:01   \n",
      "\n",
      "    reconstruction_error  \n",
      "5               0.000255  \n",
      "6               0.000255  \n",
      "16              0.000743  \n",
      "17              0.000306  \n",
      "52              0.000464  \n"
     ]
    }
   ],
   "source": [
    "# Identify anomalies\n",
    "threshold = np.percentile(mse, 95)\n",
    "anomalies = df[df['reconstruction_error'] > threshold]\n",
    "print(\"\\nTop anomalies based on reconstruction error:\")\n",
    "print(anomalies[['Locality_Name', 'Crime_Type', 'Date', 'Time', 'reconstruction_error']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
